{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('x_train.pkl').isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('x_train.pkl').loc[:, 'temp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('x_train_preprocessed.pkl').loc[:, 'temp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro = joblib.load('x_train_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro.loc[prepro.depth == 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('x_train_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operatorship(df_in, do=True):\n",
    "    \"\"\"\n",
    "    function to change operator into Pertamina & Non-Pertamina\n",
    "\n",
    "    Args:\n",
    "    - df_in(DataFrame): Input data\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    if do:\n",
    "        df['operator'] = df.apply(lambda row: 'PERTAMINA' if ('PERTAMINA' in row['operator']) else 'NON_PERTAMINA', axis=1)   \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(df_in, do=True):\n",
    "    \"\"\"\n",
    "    function for data transformatio, focus on ordinal data to become one-hot-encoded\n",
    "\n",
    "    Args:\n",
    "    - df_in(DataFrame): Input data\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    if do:\n",
    "        \n",
    "        num_df = df._get_numeric_data()\n",
    "        cat_df = df.drop(columns=num_df.columns)\n",
    "        cat_df = cat_df.drop(columns=['field_name', 'project_level'])\n",
    "        df = operatorship(df)\n",
    "\n",
    "        cat_encoder = OneHotEncoder()\n",
    "\n",
    "        hot_cat_df = cat_encoder.fit_transform(cat_df)\n",
    "        hot_cat_df_ = hot_cat_df.toarray()\n",
    "\n",
    "        cat_columns = ['Gas', 'Oil', 'Oil-Gas',\n",
    "            'NON_PERTAMINA', 'PERTAMINA', \n",
    "            'BOTH', 'OFFSHORE', 'ONSHORE', \n",
    "            'Aceh', 'Jambi', 'Jawa Barat', 'Jawa Tengah', 'Jawa Timur',\n",
    "            'Kalimantan Selatan', 'Kalimantan Tengah', 'Kalimantan Timur',\n",
    "            'Kalimantan Utara', 'Laut Cina Utara', 'Laut Jawa', 'Laut Natuna',\n",
    "            'Laut Natuna Utara', 'Laut Seram', 'Laut Timor', 'Maluku',\n",
    "            'Papua Barat', 'Riau', 'Selat Makasar', 'Selat Malaka',\n",
    "            'Sulawesi Barat', 'Sulawesi Selatan', 'Sulawesi Tengah',\n",
    "            'Sulawesi Tengah (offshore)', 'Sumatera Barat', 'Sumatera Selatan',\n",
    "            'Sumatera Utara', 'Teluk Berau', \n",
    "            'Jawa', 'Kalimantan', 'Sumatera', 'Timur']\n",
    "\n",
    "        tr_df_cat = pd.DataFrame(hot_cat_df_, columns=cat_columns)\n",
    "\n",
    "        tr_feat_df = pd.concat((num_df, tr_df_cat), axis=1)\n",
    "\n",
    "    return tr_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = joblib.load('x_train_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = xt.drop(columns=['cap_cost', 'opr_cost','total_cost', 'NPV', 'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = xt._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = xt.drop(columns=num_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = cat_df.drop(columns=['field_name', 'project_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = operatorship(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = cat_df.drop(columns=['field_name', 'project_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "hot_cat_df = cat_encoder.fit_transform(cat_df)\n",
    "hot_cat_df_ = hot_cat_df.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtp = joblib.load('x_train_preprocessed.pkl')\n",
    "xvp = joblib.load('x_valid_preprocessed.pkl')\n",
    "xtsp = joblib.load('x_test_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((xtp, xvp, xtsp), axis=0).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtf = joblib.load('x_train_feat.pkl')\n",
    "xvf = joblib.load('x_valid_feat.pkl')\n",
    "xtsf = joblib.load('x_test_feat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = xtsf.isnull().sum().sort_values(ascending=False)\n",
    "percent = (xtsf.isnull().sum()/xtsf.isnull().count()).sort_values(ascending=False)*100\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('master_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(0, decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = joblib.load('y_train.pkl')\n",
    "yv = joblib.load('y_valid.pkl')\n",
    "yts = joblib.load('y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    space = {'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "         'eta' : hp.uniform('eta', 0.01, 0.5, 0.05),\n",
    "         'gamma' : hp.uniform('gamma', 0, 2),\n",
    "         'reg_alpha' : hp.quniform('reg_alpha', 0, 50, 1),\n",
    "         'reg_lambda' : hp.uniform('reg_lambda', 0, 50),\n",
    "         'subsample' : hp.uniform('subsample', 0.5, 1),\n",
    "         'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "         'n_estimators' : hp.quniform('n_estimators', 5, 1000),\n",
    "         'seed' : 0,\n",
    "         'eval_metric' : 'auc',\n",
    "         'objective' : 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf_XGB = xgb.XGBClassifier(random_state=42, \n",
    "                            booster='gbtree', \n",
    "                            eta=best_hyperparams['eta'], \n",
    "                            gamma=best_hyperparams['gamma'], \n",
    "                            subsample=best_hyperparams['subsample'], \n",
    "                            max_depth=int(best_hyperparams['max_depth']), \n",
    "                            reg_lambda=best_hyperparams['reg_lambda'], \n",
    "                            reg_alpha=best_hyperparams['reg_alpha'],\n",
    "                            grow_policy='depthwise',\n",
    "                            n_estimators=int(best_hyperparams['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators : hp.quniform('n_estimators', 5, 1000)\n",
    "max_depth : hp.quniform('max_depth', 2, 20, 1)\n",
    "gamma : hp.uniform('gamma', 0, 2)\n",
    "reg_alpha : hp.quniform('reg_alpha', 0, 50, 1)\n",
    "reg_lambda : hp.uniform('reg_lambda', 0, 50)\n",
    "subsample : hp.uniform('subsample', 0.5, 1)\n",
    "eta : hp.uniform('eta', 0.01, 0.5, 0.05)\n",
    "min_child_weight : hp.quniform('min_child_weight', 0, 10, 1)\n",
    "seed : 0\n",
    "eval_metric : 'auc'\n",
    "objective : 'binary:logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    space = {'max_depth' : hp.choice('max_depth', np.arange(2, 20, 1, dtype=int)),\n",
    "         'eta' : hp.choice('eta', np.arange(0.01, 0.5, 0.05, dtype=float)), #float\n",
    "         'gamma' : hp.choice('gamma', np.arange(0, 2, 0.1, dtype=float)), #float\n",
    "         'reg_alpha' : hp.choice('reg_alpha', np.arange(0, 50, 1, dtype=int)),\n",
    "         'reg_lambda' : hp.choice('reg_lambda', np.arange(0, 50, 0.05, dtype=float)), #float\n",
    "         'subsample' : hp.choice('subsample', np.arange(0, 1, 0.1, dtype=float)), #float\n",
    "         'min_child_weight' : hp.choice('min_child_weight', np.arange(0, 10, 1, dtype=int)),\n",
    "         'n_estimators' : hp.choice('n_estimators', np.arange(0, 1000, 50, dtype=int)),\n",
    "         'seed' : 0,\n",
    "         'eval_metric' : 'auc',\n",
    "         'objective' : 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = int(space['n_estimators']), max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                        reg_alpha = int(space['reg_alpha']), reg_lambda = space['reg_lambda'], subsample = space['subsample'],\n",
    "                        eta = space['eta'], min_child_weight = int(space['min_child_weight']), seed = 0, \n",
    "                        eval_metric = 'auc', objective = 'binary:logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "                        columns=['fluid','operator','project_status','inplace','depth','temp',\n",
    "                        'poro','perm','saturate','api_dens','visc','avg_fluid_rate','location','region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forming = {'fluid': 'gas', 'operator': 0, 'project_status': 0,\n",
    "                    'inplace': 0, 'depth': 0, 'temp': 0, 'poro': 0,\n",
    "                    'perm': 0, 'saturate': 0, 'api_dens': 0, 'visc': 0,\n",
    "                    'avg_fluid_rate': 0, 'location': 0, 'region': 0}\n",
    "\n",
    "df = pd.DataFrame([forming])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fluid</th>\n",
       "      <th>operator</th>\n",
       "      <th>project_status</th>\n",
       "      <th>inplace</th>\n",
       "      <th>depth</th>\n",
       "      <th>temp</th>\n",
       "      <th>poro</th>\n",
       "      <th>perm</th>\n",
       "      <th>saturate</th>\n",
       "      <th>api_dens</th>\n",
       "      <th>visc</th>\n",
       "      <th>avg_fluid_rate</th>\n",
       "      <th>location</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fluid  operator  project_status  inplace  depth  temp  poro  perm  saturate  \\\n",
       "0   gas         0               0        0      0     0     0     0         0   \n",
       "\n",
       "   api_dens  visc  avg_fluid_rate  location  region  \n",
       "0         0     0               0         0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('fld_prob_indx')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed94bbebc6c6a8d799d1b7b2b0eb23a377d795e8b9280f555d2bf75239ae4f8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
